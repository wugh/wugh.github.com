<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>最大熵 &mdash; Life in a Nutshell</title>
  <meta name="author" content="Guohua Wu">

  <link href="https://wugh.github.io/feeds/main.atom.xml" type="application/atom+xml" rel="alternate"
        title="Life in a Nutshell Atom Feed" />





  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">


    <link href="https://wugh.github.io/favicon.png" rel="icon">

  <link href="https://wugh.github.io/theme/css/main.css" media="screen, projection"
        rel="stylesheet" type="text/css">

  <link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
</head>

<body>
  <header role="banner"><hgroup>
  <h1><a href="https://wugh.github.io/">Life in a Nutshell</a></h1>
</hgroup></header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="https://wugh.github.io/feeds/main.atom.xml" rel="subscribe-atom">Atom</a></li>
</ul>


<ul class="main-navigation">
    <li><a href="/archives.html">Archives</a></li>
      <li><a href="https://wugh.github.io/pages/about-me.html">About&nbsp;Me</a></li>
</ul></nav>
  <div id="main">
    <div id="content">
<div>
  <article class="hentry" role="article">
<header>
      <h1 class="entry-title">最大熵</h1>
    <p class="meta">
<time datetime="2014-11-14T00:00:00+08:00" pubdate>2014-11-14(Fri)</time>    </p>
</header>

  <div class="entry-content"><hr />
<h3>最大熵原理</h3>
<p>最大熵原理指的是当我们在估计概率分布的时候，这个概率分布符合已知信息的约束并且&nbsp;该分布是最均匀的。从熵的角度考虑就是要让这个分布符合约束并且熵最大。</p>
<blockquote>
<p>The principle of maximum entropy states that, subject to precisely stated
prior data (such as a proposition that expresses testable information), the
probability distribution which best represents the current state of knowledge
is the one with largest&nbsp;entropy.</p>
</blockquote>
<p>现在考虑一个文本分类的例子，假设我们有4个类别的文本分别是：economics、
sports、politics和art。因为文本只能被分成4个类别，假设现在没有额外的信息，&nbsp;那么约束只有以下的1个
</p>
<div class="math">$$p(economics)+p(sports)+p(politics)+p(art)=1$$</div>
<p>
那么我们希望得到得概率分布尽量均匀，就会得到下面结果
</p>
<div class="math">$$p(economics)=p(sports)=p(politics)=p(art)=0.25$$</div>
<p>
现在假设我们有一个先验信息是60%的文档是economics或者sports类别的，那么我们的&nbsp;概率分布就会有以下两个约束
</p>
<div class="math">$$p(economics)+p(sports)=0.6$$</div>
<div class="math">$$p(economics)+p(sports)+p(politics)+p(art)=1$$</div>
<p>
考虑以上两个约束又希望使得我们的分布均匀，将会得到下面的结果
</p>
<div class="math">$$
\begin{align}
\notag
p(economics)&amp;=0.30\cr
\notag
p(sports)&amp;=0.30\cr
\notag
p(politics)&amp;=0.20\cr
\notag
p(art)&amp;=0.20 
\end{align}
$$</div>
<p>
但是随着对数据的观察，可能又会对引入其他约束。这时候需要解决两个问题，首先是如
何来定量描述分布的均匀；其次是如何在考虑约束的条件下使得分布均匀。最大熵的基本
思路就是选择一个与给定事实一致的模型（满足约束），并且要使得模型对未知事实不做&nbsp;假设（使得分布尽量均匀）。</p>
<h3>最大熵建模</h3>
<p>我们继续考虑上面提到的文本分类的例子，假设用最简单的<a href="http://en.wikipedia.org/wiki/Bag-of-words_model" title="Bag-of-words model">词袋模型</a>来表示文档，&nbsp;每个文档都可以表示成一个词频向量，例如下面的简单的例子</p>
<div class="highlight"><pre><span class="n">Doc1</span><span class="o">:</span> <span class="n">John</span> <span class="n">likes</span> <span class="n">to</span> <span class="n">watch</span> <span class="n">movies</span><span class="o">.</span> <span class="n">Mary</span> <span class="n">likes</span> <span class="n">movies</span> <span class="n">too</span><span class="o">.</span>
<span class="n">Doc2</span><span class="o">:</span> <span class="n">John</span> <span class="n">also</span> <span class="n">likes</span> <span class="n">to</span> <span class="n">watch</span> <span class="n">football</span> <span class="n">games</span><span class="o">.</span>
</pre></div>


<p>得到词表如下:</p>
<div class="highlight"><pre>{
    &quot;John&quot;: 1,
    &quot;likes&quot;: 2,
    &quot;to&quot;: 3,
    &quot;watch&quot;: 4,
    &quot;movies&quot;: 5,
    &quot;also&quot;: 6,
    &quot;football&quot;: 7,
    &quot;games&quot;: 8,
    &quot;Mary&quot;: 9,
    &quot;too&quot;: 10
}
</pre></div>


<p>所以可以把Doc1和Doc2表示成两个10维的向量，如下:</p>
<div class="highlight"><pre>Doc1: [1, 2, 1, 1, 2, 0, 0, 0, 1, 1]
Doc2: [1, 1, 1, 1, 0, 1, 1, 1, 0, 0]
</pre></div>


<p>我们把当个文档用<span class="math">\(x\)</span>表示，文档类别用<span class="math">\(y\)</span>表示，根据上面的描述<span class="math">\(y\)</span>会有4个类别，跟
<a href="http://en.wikipedia.org/wiki/Logistic_regression" title="Logistic regression">Logistic Regression</a>类似，我们要建模一个判别模型<span class="math">\(p(y|x)\)</span>，即给定
一个文档<span class="math">\(x\)</span>，我们的模型可以得出这篇文档属于特定类别<span class="math">\(y\)</span>的概率。如果用<span class="math">\(\mathcal{P}\)</span>
表示所有的条件概率分布，那么<span class="math">\(p(y|x)\)</span>就是<span class="math">\(\mathcal{P}\)</span>中的一个元素。</p>
<h4>训练数据</h4>
<p>我们可以把的<span class="math">\(N\)</span>个训练数据表示成<span class="math">\(\\{(x_1,y_1),\cdots,(x_N,y_N)\\}\)</span>，且</p>
<ul>
<li><span class="math">\(x_i\in X\)</span>，其中<span class="math">\(X\)</span>表示所有的文档类别</li>
<li><span class="math">\(y_i\in Y\)</span>，其中<span class="math">\(Y\)</span>表示训练文档集合，每个文档用词频向量表示</li>
</ul>
<p>从训练数据样本中我们可以估计出一个经验的联合概率分布
</p>
<div class="math">$$\tilde{p}(x,y)=\frac{1}{N}\times \text{the number of times (x,y) appears}$$</div>
<h4>特征和约束</h4>
<p>最大熵建模的过程中特征函数（简称特征）主要是为了描述训练样本的统计量，例如&nbsp;建模的时候我们可能会考虑当ball这个词出现的时候，文档属于sports的概率是9/10。</p>
<p>为了描述ball出现时文档属于sports类别的事实我们引入特征函数（指示函数或者特征）
</p>
<div class="math">$$
f_{ball,sports} (x,y)=\begin{cases}
1 &amp; \text{if y=sports and ball appears in d} \cr
0 &amp; \text{otherwise}
\end{cases}
$$</div>
<p>
考虑经验分布<span class="math">\(\tilde{p}(x,y)\)</span>下<span class="math">\(f\)</span>的期望值，这个期望值就是我们关注的统计量（如
果对上面那个特征函数按照经验分布求期望，得到的东西就是当ball这个词出现的时候文&nbsp;档属于sports的概率），记为
</p>
<div class="math">$$
\begin{equation}
\tilde{p}(f)\equiv \sum_{x,y}{\tilde{p}(x,y)f(x,y)}
\end{equation}
\label{eq:empricalException}
$$</div>
<p>
其实样本的任何统计量都可以通过特征函数的期望值来表示。</p>
<p>如果我们发现了一些有用的统计量，我们就可以要求我们的模型也要遵循这个信息。我们
通过约束模型在特征函数<span class="math">\(f\)</span>上的期望值来遵循这个统计量，对于模型<span class="math">\(p(y|x)\)</span>特征函数
<span class="math">\(f\)</span>的期望值为
</p>
<div class="math">$$
\begin{equation}
p(f)\equiv \sum_{x,y}{\tilde{p}(x)p(y|x)f(x,y)}
\label{eq:modelException}
\end{equation}
$$</div>
<p>
其中<span class="math">\(\tilde{p}(x)\)</span>是训练样本中<span class="math">\(x\)</span>的经验分布。我们通过约束模型下特征函数的期望&nbsp;值等于样本中特征函数的期望值，如下所示
</p>
<div class="math">$$
\begin{equation}
p(f) = \tilde{p}(f)
\label{eq:constriant}
\end{equation}
$$</div>
<p>把前面的<span class="math">\(\ref{eq:empricalException}\)</span>，<span class="math">\(\ref{eq:modelException}\)</span>和
<span class="math">\(\ref{eq:constriant}\)</span>综合起来得意得到下面的约束</p>
<div class="math">$$
\sum_{x,y}{\tilde{p}(x)p(y|x)f(x,y)} = \sum_{x,y}{\tilde{p}(x,y)f(x,y)}
$$</div>
<p>这样我们只需要考虑那些满足<span class="math">\(\ref{eq:constriant}\)</span>的模型<span class="math">\(p(y|x)\)</span>。总的来说
我们用<span class="math">\(\tilde{p}(f)\)</span>表示样本数据中的统计特征，同时也要求我们的模型要表示出
这种特征（<span class="math">\(p(f)=\tilde{p}(f)\)</span>）。</p>
<p>假设我们现在有<span class="math">\(n\)</span>个我们认为很重要的特征函数<span class="math">\(f_i\)</span>，我们希望我们的模型遵循这些
特征在训练数据中所表现出的统计信息，那么<span class="math">\(p\)</span>就应该是<span class="math">\(\mathcal{P}\)</span>的一个子集
<span class="math">\(\mathcal{C}\)</span>，定义如下
</p>
<div class="math">$$
\begin{equation}
\mathcal{C} = \big\{p \in P \text{ | } p(f_i)=\tilde{p}(f_i) \text{ for i } \in \{1,2,\cdots,n\}\big\}
\label{eq:distsubset}
\end{equation}
$$</div>
<p>
下图解释为概率分布添加约束的过程，图中<span class="math">\(\mathcal{P}\)</span>表示一个在3个变量上的概率分
布，如果我们没有设置任何约束那么所有的概率分布都是可以的如图(a)所示；如果我们
添加一个线性约束<span class="math">\(\mathcal{C}_1\)</span>那么我们的概率分布只能落在图(b)中<span class="math">\(mathcal{C}_1\)</span>
这个线上面；此时如果再添加一个约束我们就能确定概率分布<span class="math">\(p\)</span>，如果第二个线性约束
<span class="math">\(\mathcal{C}_2\)</span>和<span class="math">\(\mathcal{C}_1\)</span>不冲突（有交点），那么这个交点就是我们要求的概
率分布<span class="math">\(p\)</span>，如图(c)所示；如果两个约束冲突，例如第一个约束要求第1点的概率是<span class="math">\(1/3\)</span>
而第二个约束是要求第3点的概率是<span class="math">\(3/4\)</span>，那么会得到图(d)的结果。由于我们的约束都
是从训练样本中抽取的，所以约束之间不可能冲突，而且我们的约束无法像图(c)一样唯
一确定<span class="math">\(p\)</span>，换句话说<span class="math">\(\mathcal{C}=\mathcal{C}_1\cap\mathcal{C}_2\cdots\cap\mathcal{C}_n\)</span>
所确定的模型有无数个。
<img alt="simplex" src="https://wugh.github.io/images/ML/simplex.png" title="simplex" /></p>
<p>在所有的模型<span class="math">\(p\in\mathcal{C}\)</span>中我们需要根据最大熵原理选择一个最均匀的，我们用
<a href="http://en.wikipedia.org/wiki/Conditional_entropy" title="条件熵">条件熵</a>量化度量条件分布<span class="math">\(p(y|x)\)</span>的均匀程度
</p>
<div class="math">$$
\begin{equation}
H(p)\equiv -\sum_{x,y}{\tilde{p}(x)p(y|x)\log{p(y|x)}}
\label{eq:conditionalentropy}
\end{equation}
$$</div>
<p>
条件熵的取值其下界是0（没有不确定性），上界是<span class="math">\(\log{|Y|}\)</span>（在所有<span class="math">\(y\)</span>的取值上均
匀分布）。我们的目的就是要从<span class="math">\(\mathcal{C}\)</span>里面找到一个模型<span class="math">\(p^*\in\mathcal{C}\)</span>使
得<span class="math">\(H(p)\)</span>最大，即
</p>
<div class="math">$$
\begin{equation}
p^*= \mathop{\arg\,\max}\limits_{p\in\mathcal{C}}H(p)
\end{equation}
$$</div>
<h3>指数形式</h3>
<p>经过上节的分析其实可以知道最大熵模型的目的就是要找到一个模型
<span class="math">\(p^*\in\mathcal{C}\)</span>使得<span class="math">\(H(p)\)</span>最大。这其实就是一个有约束条件下的最优化问题，可
以用<a href="https://en.wikipedia.org/wiki/Lagrange_multiplier" title="拉格朗日数乘">拉格朗日乘数法</a>来解，原始优化问题形式如下：
</p>
<div class="math">$$
\begin{align*}
&amp; max_p &amp;&amp; H(p) \\
&amp; s.t. &amp;&amp; p(y|x) \leq 0\text{ for all }x,y.\\
&amp;&amp;&amp; \sum_yp(y|x)=1\text{ for all }x. \\
&amp;&amp;&amp; \sum_{x,y}\tilde{p}(x)p(y|x)f(x,y)=\sum_{x,y}\tilde{p}(x,y)f(x,y)\text{ for }
i\in\left\{1,2,...,n\right\}. 
\end{align*}
$$</div>
<p>
前两个约束保证模型是一个条件概率分布，第三个约束值得是模型需要满足的统计量。该
问题等价于在相同约束下最小化<span class="math">\(-H(p)\)</span>：
</p>
<div class="math">$$\begin{equation}\begin{split}
&amp; min_p &amp;&amp; -H(p) \\
&amp; s.t. &amp;&amp; p(y|x) \leq 0\text{ for all }x,y.\\
&amp;&amp;&amp; \sum_yp(y|x)=1\text{ for all }x.\\
&amp;&amp;&amp; \sum_{x,y}\tilde{p}(x)p(y|x)f(x,y)=\sum_{x,y}\tilde{p}(x,y)f(x,y)\text{ for }
i\in\left\{1,2,...,n\right\}.
\end{split}
\label{eq:primal}
\end{equation}$$</div>
<p>
用拉格朗日乘数法将有约束问题转换成无约束问题，拉格朗日方程如下：
</p>
<div class="math">$$\begin{equation}\begin{split}
\mathcal{L}(p,\Lambda,\gamma)=&amp;\sum_{x,y}\tilde{p}(x)p(y|x)\log p(y|x)\\
&amp;+\sum_i^n\lambda_i\left(sum_{x,y}\tilde{p}(x,y)f_i(x,y)-\sum_{x,y}\tilde{p}(x)p(y|x)f_i(x,y)\right)\\
&amp;+\gamma(\sum_yp(y|x) - 1)
\end{split}
\label{eq:lagrangian}
\end{equation}$$</div>
<p>
对于<span class="math">\(\ref{eq:lagrangian}\)</span>这个拉格朗日方程原问题如下：
</p>
<div class="math">$$\begin{equation}
\min_w\max_{\Lambda,\gamma}\mathcal{L}(p,\Lambda,\gamma)
\end{equation}$$</div>
<p>
对偶问题为：
</p>
<div class="math">$$\begin{equation}
\max_{\Lambda,\gamma}\min_w\mathcal{L}(p,\Lambda,\gamma)
\label{eq:dual}
\end{equation}$$</div>
<p>
由于<span class="math">\(p\)</span>是一个凸函数，并且两个约束都和<span class="math">\(p\)</span>呈线性关系，所以原始问题的解和对偶问题
的解是等价的，下面求如何最大化对偶问题<span class="math">\(\ref{eq:dual}。首先固定\)</span>Lambda<span class="math">\(和
$\gamma\)</span>求<span class="math">\(\mathcal{L}(p,\Lambda,\gamma)\)</span>的最小值，将<span class="math">\(\ref{eq:lagrangian}\)</span>对
<span class="math">\(p\)</span>求导，另求导结果等于0，得到：
</p>
<div class="math">$$
\frac{\partial \mathcal{L}(p,\Lambda,\gamma)}{\partial
p(y|x)}=\tilde{p}(x)\left(1+\log
p(y|x)\right)-\sum_i\lambda_i\tilde{p}(x)f_i(x,y) + \gamma=0
$$</div>
<p>
可以求得最优的<span class="math">\(p(y|x)\)</span>具有如下形式：
</p>
<div class="math">$$\begin{equation}\begin{split}
&amp;\log p^*(y|x)=\sum_i\lambda_if_i(x,y)-\frac{\gamma}{\tilde{p}(x)}-1\\
\Rightarrow&amp;p*(y|x)=\exp\left(\sum_i\lambda_if_i(x,y)\right)\exp\left(-\frac{\gamma)}{\tilde{p}(x)}-1\right)
\end{split}
\label{eq:optimalp}
\end{equation}$$</div>
<p>
这样我们就找到了<span class="math">\(p^*\)</span>的最优化形式，现在的目标就是要去求解<span class="math">\(\gamma^*\)</span>和
<span class="math">\(\Lambda^*\)</span>。注意到<span class="math">\(\ref{eq:optimalp}\)</span>的第二项实际上对应的就是原始束问题
<span class="math">\(\ref{eq:primal}\)</span>的第二个约束，可以把<span class="math">\(\ref{eq:optimalp}\)</span>写成如下形式：
</p>
<div class="math">$$\begin{equation}\begin{split}
p*(y|x)&amp;=\frac{p^*(y|x)}{\sum_yp^*(y|x)}\\
&amp;=\frac{\exp\left(\sum_i\lambda_if_i(x,y)\right)\exp\left(-\frac{\gamma)}{\tilde{p}(x)}-1\right)}{\sum_y{\exp\left(\sum_i\lambda_if_i(x,y)\right)\exp\left(-\frac{\gamma)}{\tilde{p}(x)}-1\right)}}\\
&amp;=\frac{\exp\left(\sum_i\lambda_if_i(x,y)\right)}{Z(x)}
\end{split}
\label{eq:optimalpnew}
\end{equation}$$</div>
<p>
其中
</p>
<div class="math">$$\begin{equation}
Z(x)=\sum_y\exp\left(\sum_i\lambda_if_i(x,y)\right)
\end{equation}$$</div>
<p>
<span class="math">\(\ref{eq:optimalpnew}\)</span>就是最终<span class="math">\(p^*\)</span>的参数形式，并且满足<span class="math">\(\ref{eq:primal}\)</span>的第二
个约束，此时相当于我们已经找到了最优的<span class="math">\(p^*\)</span>和<span class="math">\(\gamma^*\)</span>，<span class="math">\(p^*\)</span>带入
拉格朗日方程<span class="math">\(\ref{eq:lagrangian}\)</span>中，得到对偶函数：
</p>
<div class="math">$$ \begin{align}
\Psi(\Lambda)&amp;=\mathcal{L}(p^*,\Lambda,\gamma^*)\nonumber\\
&amp;=\sum_{x,y}\tilde{p}(x)p^*(y|x)\log p^*(y|x)+\sum_i^n\lambda_i\left(\sum_{x,y}\tilde{p}(x,y)f_i(x,y)-\sum_{x,y}\tilde{p}(x)p^*(y|x)f_i(x,y)\right)\nonumber\\
&amp;=\sum_{x,y}\tilde{p}(x,y)\sum_i\lambda_i f_i(x,y)+\sum_{x,y}\tilde{p}(x)p^*(y|x)\left(\log p^*(y|x)-\sum_i\lambda_i f_i(x,y)\right)\nonumber\\
&amp;=\sum_{x,y}\tilde{p}(x,y)\sum_i\lambda_i f_i(x,y)-\sum_{x,y}\tilde{p}(x)p^*(y|x)\log Z(x)\nonumber\\
&amp;=\sum_{x,y}\tilde{p}(x,y)\sum_i\lambda_i f_i(x,y)-\sum_{x}\tilde{p}(x)\log Z(x)
\label{eq:optimallambda}
\end{align} $$</div>
<p>
所以现在的对偶问题<span class="math">\(\ref{eq:dual}\)</span>相当于是要优化如下目标：
</p>
<div class="math">$$ \begin{align}
\max_{\Lambda}\Psi(\Lambda)=\max_{\Lambda}\left[\sum_{x,y}\tilde{p}(x,y)\sum_i\lambda_i f_i(x,y)-\sum_{x}\tilde{p}(x)\log Z(x)\right]
\end{align} $$</div>
<p>
最优的<span class="math">\(\Lambda^*\)</span>需要满足：
</p>
<div class="math">$$ \begin{align}
\DeclareMathOperator*{\argmax}{arg\,max}
\Lambda^*=\argmax_{\Lambda}\Psi(\Lambda)=\argmax_{\Lambda}\left[\sum_{x,y}\tilde{p}(x,y)\sum_i\lambda_i f_i(x,y)-\sum_{x}\tilde{p}(x)\log Z(x)\right]
\end{align} $$</div>
<h3>最大似然</h3>
<p>已知训练数据的经验分布<span class="math">\(\tilde{p}(x,y)\)</span>，模型<span class="math">\(p(y|x)\)</span>的对数似然函数表示为：
</p>
<div class="math">$$\begin{align}
L_{\tilde{p}}(p) &amp;\equiv \log\Pi_{x,y}p(y|x)^{\tilde{p}(x,y)}=\sum_{x,y}\tilde{p}(x,y)\log p(y|x) \nonumber \\
&amp;=\sum_{x,y}\tilde{p}(x,y)\sum_i\lambda_i f_i(x,y)-\sum_{x,y}\tilde{p}(x,y)\log Z(x) \nonumber \\G
&amp;=\sum_{x,y}\tilde{p}(x,y)\sum_i\lambda_i f_i(x,y)-\sum_{x,y}\tilde{p}(x)\log Z(x)
\label{eq:likehood}
\end{align}$$</div>
<p>
可以看出对偶函数<span class="math">\(\Psi(\Lambda)\)</span>形式<span class="math">\(\ref{eq:optimallambda}\)</span>和模型<span class="math">\(p\)</span>的对数似然
结果是等价的。所以整个对偶问题的求解找到的熵最大的模型<span class="math">\(p*\)</span>其实也最大化了模型在&nbsp;训练样本上的似然。</p>
<h3>参数求解</h3>
<p>对于一般的问题一般无法用数学分析的方法求解出最大化<span class="math">\(\Psi(\Lambda)\)</span>的<span class="math">\(\Lambda^*\)</span>
，一般需要用数值方法来求解。因为<span class="math">\(\Psi(\Lambda)\)</span>是一个光滑的凸函数，所以有很多
方法都可以用来求<span class="math">\(\Lambda^*\)</span>，例如梯度下降、共轭梯度、坐标上升等方法。这里介绍
的是专门针对最大熵问题设计的<code>改进的尺度迭代算法（improved iterative scaling,
IIS）</code>，该算法要求所有的特征函数<span class="math">\(f_i(x,y)\)</span>必须非负。
<img alt="IIS算法" src="https://wugh.github.io/images/ML/iis.png" />
算法的关键在于求解第3步的<span class="math">\(\Delta\lambda_i\)</span>，如果这时候<span class="math">\(f^\#(x,y)\)</span>（表示某个样
本<span class="math">\(x,y\)</span>激活的特征函数个数）对于所有的<span class="math">\(x,y\)</span>都一样，即<span class="math">\(f^\#(x,y)\)</span>是一个常数<span class="math">\(M\)</span>，
那么<span class="math">\(\Delta\lambda_i\)</span>可以按下面式子求解
</p>
<div class="math">$$
\Delta\lambda_i = \frac{1}{M}\log\frac{\tilde{p}(f_i)}{p_\Lambda(f_i)}
$$</div>
<p>
如果<span class="math">\(f^\#(x,y)\)</span>不是一个常数，那么<span class="math">\(\Delta\lambda_i\)</span>需要通过数值方法计算。一个简
单快速的方法是通过<a href="https://en.wikipedia.org/wiki/Newton%27s_method" title="牛顿法">牛顿法</a>来求解，相当于这时候的目标函数
<span class="math">\(g(\Delta\lambda_i)\)</span>就是算法第3步那个方程把右边那一项移到左边的函数，现在的目
标就是要求<span class="math">\(g(\Delta\lambda_i)=0\)</span>的<span class="math">\(\Delta\lambda_i\)</span>，可以按下面的更新公式求
</p>
<div class="math">$$\begin{equation}
\Delta\lambda_i^{n+1}=\Delta\lambda_i^n-\frac{g(\Delta\lambda_i^n)}{g'(\Delta\lambda_i^n)}
\end{equation}$$</div>
<p>
通过选取适当的初始<span class="math">\(\Delta\lambda_i^0\)</span>，由于<span class="math">\(g(\Delta\lambda_i)=0\)</span>有单根，牛顿&nbsp;法可以快速收敛。</p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script></div>
    <footer>
<p class="meta">
  <span class="byline author vcard">
    Posted by <span class="fn">
        Guohua Wu
    </span>
  </span>
<time datetime="2014-11-14T00:00:00+08:00" pubdate>2014-11-14(Fri)</time>  <span class="categories">
    <a class='category' href='https://wugh.github.io/category/machine-learning.html'>Machine Learning</a>
  </span>
  <span class="categories">
    <a class="category" href="https://wugh.github.io/tag/maxent.html">MaxEnt</a>  </span>
</p><div class="sharing">
</div>    </footer>
  </article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div>
  </section>
</div>
<aside class="sidebar">
  <section>
    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="https://wugh.github.io/posts/2016/02/cs224d-notes1-word2vec/">CS224D笔记1——word2vec</a>
      </li>
      <li class="post">
          <a href="https://wugh.github.io/posts/2015/09/pelican-custom-jinja-filter/">Pelican自定义Jinja过滤器</a>
      </li>
      <li class="post">
          <a href="https://wugh.github.io/posts/2015/01/linux-pulse-mix-mic-and-computer-audio/">Linux通过Pulse混合麦克风和音频输出</a>
      </li>
      <li class="post">
          <a href="https://wugh.github.io/posts/2014/11/maxent/">最大熵</a>
      </li>
      <li class="post">
          <a href="https://wugh.github.io/posts/2014/04/an-introduction-to-mdp/">MDP入门</a>
      </li>
    </ul>
  </section>
  <section>
      
    <h1>Categories</h1>
    <ul id="recent_posts">
        <li><a href="https://wugh.github.io/category/linux.html">Linux</a></li>
        <li><a href="https://wugh.github.io/category/machine-learning.html">Machine Learning</a></li>
        <li><a href="https://wugh.github.io/category/nlp.html">NLP</a></li>
        <li><a href="https://wugh.github.io/category/web.html">Web</a></li>
    </ul>
  </section>
 

  <section>
  <h1>Tags</h1>
    <a href="https://wugh.github.io/tag/pelican.html">Pelican</a>,    <a href="https://wugh.github.io/tag/lu-yin.html">录音</a>,    <a href="https://wugh.github.io/tag/pulse.html">pulse</a>,    <a href="https://wugh.github.io/tag/vim.html">vim</a>,    <a href="https://wugh.github.io/tag/ap.html">ap</a>,    <a href="https://wugh.github.io/tag/mp3.html">mp3</a>,    <a href="https://wugh.github.io/tag/mdp.html">MDP</a>,    <a href="https://wugh.github.io/tag/shen-du-xue-xi.html">深度学习</a>,    <a href="https://wugh.github.io/tag/jinja.html">Jinja</a>,    <a href="https://wugh.github.io/tag/hexo.html">hexo</a>,    <a href="https://wugh.github.io/tag/nei-he-bian-yi.html">内核编译</a>,    <a href="https://wugh.github.io/tag/portage.html">Portage</a>,    <a href="https://wugh.github.io/tag/fontconfig.html">fontconfig</a>,    <a href="https://wugh.github.io/tag/luan-ma.html">乱码</a>,    <a href="https://wugh.github.io/tag/word2vec.html">word2vec</a>,    <a href="https://wugh.github.io/tag/gentoo.html">Gentoo</a>,    <a href="https://wugh.github.io/tag/wen-ben-fen-lei.html">文本分类</a>,    <a href="https://wugh.github.io/tag/latex.html">latex</a>,    <a href="https://wugh.github.io/tag/svm.html">SVM</a>,    <a href="https://wugh.github.io/tag/hostapd.html">hostapd</a>,    <a href="https://wugh.github.io/tag/ge-shi-zhuan-huan.html">格式转换</a>,    <a href="https://wugh.github.io/tag/maxent.html">MaxEnt</a>,    <a href="https://wugh.github.io/tag/filter.html">Filter</a>  </section>


    <section>
        <h1>Social</h1>
        <ul>
            <li><a href="https://wugh.github.io/feeds/main.atom.xml" type="application/atom+xml" rel="alternate">Atom</a></li>
            <li><a href="https://github.com/wugh" target="_blank">GitHub</a></li>
        </ul>
    </section>

</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
    Copyright &copy;  2013&ndash;2016  Guohua Wu &mdash;
  <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>
  <script src="https://wugh.github.io/theme/js/modernizr-2.0.js"></script>
  <script src="https://wugh.github.io/theme/js/ender.js"></script>
  <script src="https://wugh.github.io/theme/js/octopress.js" type="text/javascript"></script>
  <script type="text/javascript">
    var disqus_shortname = 'guohuasblog';
    var disqus_identifier = '/posts/2014/11/maxent/';
    var disqus_url = 'https://wugh.github.io/posts/2014/11/maxent/';
    var disqus_title = '最大熵';
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = "//" + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
     })();
  </script>
</body>
</html>